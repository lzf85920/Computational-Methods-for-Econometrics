{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econ 7218 Problem Set 1 \n",
    "*r09323036 經濟所碩一 李祖福*\n",
    "\n",
    "\n",
    "For this course, it will be necessary to use a general or scientific programming language such as Matlab, Python, or R. The goal of this problem set is to learn the basics of such tools by simulating and estimating a simple discrete choice model via numerical optimization algorithms.\n",
    "\n",
    "Consider a simple binary choice model where unobserved error terms U1 and U2 are both standard type-I value distributed with cdf\n",
    "\n",
    "$$F (u) = e^{e^{(-u)}}$$\n",
    "\n",
    "and where there are two covariates $X_1$ ∼ $N(0,1)$ and $X_2$ ∼ $\\chi^2(1)$.\n",
    "\n",
    "$$f(x)=\n",
    "\\begin{cases}\n",
    "1& if\\ \\ X_{1i}\\beta_1 +U_{1i} >X_{2i}\\beta_2 +U_{2i}\\\\\n",
    "0& otherwise\n",
    "\\end{cases}$$\n",
    "\n",
    "The resulting probability function of $y_i$ is\n",
    "$$\n",
    "P r(y_i = 1|X_{1i}, X_{2i}) = \\dfrac{exp(X_{1i}\\beta_1 − X_{2i}\\beta_2) }{1 + exp(X_{1i}\\beta_1 − X_{2i}\\beta_2)}\n",
    "$$\n",
    "\n",
    "Suppose that $\\beta_1$ = 1.0 and $\\beta_2$ = −0.5.\n",
    "\n",
    "\n",
    "---\n",
    "### Q1. Simulate a dataset of size N = 400 from the model for a given set of parameter values ($\\beta_1, \\beta_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "u1 = np.random.gumbel(0, 1, 400)\n",
    "u2 = np.random.gumbel(0, 1, 400)\n",
    "x1 = np.random.normal(0, 1, 400)\n",
    "x2 = np.random.chisquare(1, 400)\n",
    "\n",
    "beta1 = np.zeros(400) + 1\n",
    "beta2 = np.zeros(400) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ((x1 * beta1) + u1) - ((x2 * beta2) + u2)\n",
    "y[y > 0] = 1\n",
    "y[y < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Code the log likelihood function as a function of the parameters ($\\beta_1, \\beta_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.exp(x1*beta1 - x2*beta2) / (1 + np.exp(x1*beta1 - x2*beta2))\n",
    "f = (y*np.log(G) + (1 - y)*np.log(1 - G)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Code a grid search algorithm over the parameter space $\\beta_1 ∈ [−5, 5]$ and $\\beta_2 ∈ [−5, 5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(n):\n",
    "    beta_1 = np.array(np.arange(-5, 5, n))\n",
    "    beta_2 = np.array(np.arange(-5, 5, n))\n",
    "\n",
    "    f_max = -1000\n",
    "    \n",
    "    for i in beta_1:\n",
    "        for j in beta_2:\n",
    "            G = np.exp(x1*i - x2*j) / (1 + np.exp(x1*i - x2*j))\n",
    "            f = (y*np.log(G) + (1 - y)*np.log(1 - G)).sum()\n",
    "             \n",
    "            if f > f_max:\n",
    "                f_max = f\n",
    "                \n",
    "                beta1_hat = i\n",
    "                beta2_hat = j\n",
    "\n",
    "\n",
    "    return beta1_hat, beta2_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in multiply\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_1 :  1.050000000000086\n",
      "Beta_2 :  -0.5499999999999368\n",
      "Time :  6.388754844665527\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "beta1, beta2 = grid_search(0.025)\n",
    "end = time.time()\n",
    "\n",
    "print('Beta_1 : ' , beta1)\n",
    "print('Beta_2 : ' , beta2)\n",
    "print('Time : ', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Generate R = 100 samples of size N = 400 in Step 1. Estimate the model for each sample with a gradient method (BHHH, BFGS, etc.) or Nelder-Mead to maximize the log likelihood function and report the mean and standard deviation of the parameter estimates across the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation():\n",
    "    u1 = np.random.gumbel(0, 1, 400)\n",
    "    u2 = np.random.gumbel(0, 1, 400)\n",
    "    x1 = np.random.normal(0, 1, 400)\n",
    "    x2 = np.random.chisquare(1, 400)\n",
    "\n",
    "    beta1 = np.zeros(400) + 1\n",
    "    beta2 = np.zeros(400) - 0.5\n",
    "    \n",
    "    y = ((x1 * beta1) + u1) - ((x2 * beta2) + u2)\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = 0\n",
    "    X = np.hstack((x1.reshape(-1,1), -x2.reshape(-1,1)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    X, y = data_generation()\n",
    "    clf = LogisticRegression(solver = 'lbfgs').fit(X, y)\n",
    "    coe = pd.DataFrame(clf.coef_)\n",
    "    coef = coef.append(coe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_mean = coef[0].mean()\n",
    "beta1_std = coef[0].std()\n",
    "\n",
    "beta2_mean = coef[1].mean()\n",
    "beta2_std = coef[1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta1_mean :  1.0048534141532368\n",
      "beta1_std :  0.14813373892553924\n",
      "beta2_mean :  -0.5045598169036059\n",
      "beta2_std :  0.11674981631392355\n"
     ]
    }
   ],
   "source": [
    "print('beta1_mean : ', beta1_mean)\n",
    "print('beta1_std : ', beta1_std)\n",
    "print('beta2_mean : ', beta2_mean)\n",
    "print('beta2_std : ', beta2_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
